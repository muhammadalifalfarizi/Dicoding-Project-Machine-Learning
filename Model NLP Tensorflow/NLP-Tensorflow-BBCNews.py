# -*- coding: utf-8 -*-
"""Submission 1 Model NLP TF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xiChz8GsoY98r6AKsL4ffxg7rPJj1RDv

# **MUHAMMAD ALIF ALFARIZI**

# **1494037162101-564**

**Mengubah Dataset menjadi Dataframe menggunakan library pandas**
"""

import pandas as pd
df = pd.read_csv('bbc-news-data.csv', sep='\t')
df

"""**Membuang 'filename' dan 'title' karena kita hanya akan menggunakan category sebagai atribut untuk dilatih pada model**"""

df.drop(['filename', 'title'], axis=1, inplace=True)
df.info()

"""**Proses one-hot-encoding dan membuat dataframe baru**"""

category = pd.get_dummies(df.category)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns=['category'])

df_baru.info()

"""**Mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values**"""

contents = df_baru['content'].values
label = df_baru[['business', 'entertainment', 'politics', 
                 'sport', 'tech']].values
label

"""**Melatih Model dan menggunakan fungsi Tokenizer**"""

from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

contents_latih, contents_test, label_latih, label_test = train_test_split(contents, label, test_size=0.2)

tokenizer = Tokenizer(num_words=10000, oov_token='x')
tokenizer.fit_on_texts(contents_latih)
tokenizer.fit_on_texts(contents_test)

sequence_latih = tokenizer.texts_to_sequences(contents_latih)
sequence_test = tokenizer.texts_to_sequences(contents_test)

padded_latih = pad_sequences(sequence_latih)
padded_test = pad_sequences(sequence_test)

"""**Menerapkan Model Sequential, Embedding, dan LSTM dalam arsitektur model serta Dropout dan Regularizer agar menghindari Overfitting**"""

import tensorflow as tf
from tensorflow import keras
from keras import regularizers
from tensorflow.keras import layers

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=10000, output_dim=32),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(5, activation='softmax')
])
opt = keras.optimizers.Adam(learning_rate=0.01)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

"""**Implementasi Callback pada Epochs**"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.8):
      print('\nAkurasi telah mencapai target')
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 30
history = model.fit(padded_latih, label_latih, batch_size=64, epochs=num_epochs,
                    validation_data=(padded_test, label_test), verbose=2)

"""**Plot Loss dan Accuracy**"""

import matplotlib.pyplot as plt

plt.title('Model Loss')
plt.plot(history.history['loss'], label='Training')
plt.plot(history.history['val_loss'], label='Validation')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='best')
plt.show()

plt.title('Model Accuracy')
plt.plot(history.history['accuracy'], label='Training')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='best')
plt.show()